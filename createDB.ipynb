{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f \n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from scipy import signal\n",
    "from scipy.signal import get_window\n",
    "from librosa.filters import mel\n",
    "from numpy.random import RandomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_highpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = signal.butter(order, normal_cutoff, btype='high', analog=False)\n",
    "    return b, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pySTFT(x, fft_length=1024, hop_length=256):\n",
    "    \n",
    "    x = np.pad(x, int((fft_length//2)), mode='reflect')\n",
    "    \n",
    "    noverlap = fft_length - hop_length\n",
    "    shape = x.shape[:-1]+((x.shape[-1]-noverlap)//hop_length, fft_length)\n",
    "    strides = x.strides[:-1]+(hop_length*x.strides[-1], x.strides[-1])\n",
    "    result = np.lib.stride_tricks.as_strided(x, shape=shape,\n",
    "                                             strides=strides)\n",
    "    \n",
    "    fft_window = get_window('hann', fft_length, fftbins=True)\n",
    "    result = np.fft.rfft(fft_window * result, n=fft_length).T\n",
    "    \n",
    "    return np.abs(result)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "mel_basis = mel(16000, 1024, fmin=90, fmax=7600, n_mels=80).T\n",
    "min_level = np.exp(-100 / 20 * np.log(10))\n",
    "b, a = butter_highpass(30, 16000, order=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "# audio file directory\n",
    "rootDir = './wavs2'\n",
    "# spectrogram directory\n",
    "targetDir = './spmel2'\n",
    "! rm -rf spmel2\n",
    "! rm -rf './spmel2/.ipynb_checkpoints'\n",
    "! rm -rf './wavs2/.ipynb_checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirName, subdirList, _ = next(os.walk(rootDir))\n",
    "print('Found directory: %s' % dirName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "for subdir in tqdm(sorted(subdirList)):\n",
    "#     print(subdir) # 224\n",
    "    if not os.path.exists(os.path.join(targetDir, subdir)):\n",
    "        os.makedirs(os.path.join(targetDir, subdir))\n",
    "    _,_, fileList = next(os.walk(os.path.join(dirName,subdir)))\n",
    "    prng = RandomState(int(subdir[2:]))\n",
    "#     prng = int(2) \n",
    "    for fileName in sorted(fileList):\n",
    "        # Read audio file        \n",
    "        x, fs = sf.read(os.path.join(dirName,subdir,fileName))\n",
    "#         print (\"x:{}\".format(x)) # emb \n",
    "        # Remove drifting noise\n",
    "        y = signal.filtfilt(b, a, x)\n",
    "        # Ddd a little random noise for model roubstness\n",
    "        wav = y * 0.96 + (prng.rand(y.shape[0])-0.5)*1e-06\n",
    "        # Compute spect\n",
    "        D = pySTFT(wav).T\n",
    "        # Convert to mel and normalize\n",
    "        D_mel = np.dot(D, mel_basis)\n",
    "        D_db = 20 * np.log10(np.maximum(min_level, D_mel)) - 16\n",
    "        S = np.clip((D_db + 100) / 100, 0, 1)    \n",
    "#         print (S.shape)\n",
    "        # save spect    \n",
    "#         print (os.path.join(targetDir, subdir, fileName[:-4]))\n",
    "        np.save(os.path.join(targetDir, subdir, fileName[:-4]),\n",
    "                S.astype(np.float32), allow_pickle=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate speaker embeddings and metadata for training\n",
    "\"\"\"\n",
    "import os\n",
    "import pickle\n",
    "from model_bl import D_VECTOR\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "C = D_VECTOR(dim_input=80, dim_cell=768, dim_emb=256).eval().cuda()\n",
    "c_checkpoint = torch.load('3000000-BL.ckpt')\n",
    "new_state_dict = OrderedDict()\n",
    "for key, val in c_checkpoint['model_b'].items():\n",
    "    new_key = key[7:]\n",
    "    new_state_dict[new_key] = val\n",
    "C.load_state_dict(new_state_dict)\n",
    "num_uttrs = 10\n",
    "len_crop = 128\n",
    "\n",
    "# Directory containing mel-spectrograms\n",
    "rootDir = './spmel2'\n",
    "! rm -rf './spmel2/.ipynb_checkpoints'\n",
    "dirName, subdirList, _ = next(os.walk(rootDir))\n",
    "# print('Found directory: %s' % dirName)\n",
    "\n",
    "speakers = []\n",
    "metadata = []\n",
    "for speaker in tqdm(sorted(subdirList)):\n",
    "#     print('Processing speaker: %s' % speaker)        \n",
    "    m=[]        \n",
    "    m.append(speaker) \n",
    "    \n",
    "    utterances = []\n",
    "    utterances.append(speaker) \n",
    "    print(speaker) # 0\n",
    "    _, _, fileList = next(os.walk(os.path.join(dirName,speaker)))\n",
    "    \n",
    "    # make speaker embedding\n",
    "    assert len(fileList) >= num_uttrs\n",
    "    idx_uttrs = np.random.choice(len(fileList), size=num_uttrs, replace=False)\n",
    "    embs = []\n",
    "    for i in range(num_uttrs):\n",
    "        tmp = np.load(os.path.join(dirName, speaker, fileList[idx_uttrs[i]]))\n",
    "        candidates = np.delete(np.arange(len(fileList)), idx_uttrs)\n",
    "        # choose another utterance if the current one is too short\n",
    "        while tmp.shape[0] < len_crop:\n",
    "            idx_alt = np.random.choice(candidates)\n",
    "            tmp = np.load(os.path.join(dirName, speaker, fileList[idx_alt]))\n",
    "            candidates = np.delete(candidates, np.argwhere(candidates==idx_alt))\n",
    "        print (tmp.shape[0])\n",
    "        print (len_crop)\n",
    "        left = np.random.randint(0, tmp.shape[0]-len_crop)\n",
    "        melsp_cpu=tmp[np.newaxis, left:left+len_crop, :]\n",
    "        melsp = torch.from_numpy(melsp_cpu).cuda()        \n",
    "        emb = C(melsp)\n",
    "        emb_cpu=emb.detach().squeeze().cpu().numpy()\n",
    "#         print (emb_cpu) #1\n",
    "        embs.append(emb_cpu)     \n",
    "    utterances.append(np.mean(embs, axis=0))\n",
    "    \n",
    "    m.append(np.mean(embs, axis=0))\n",
    "    m.extend(melsp_cpu)\n",
    "    metadata.append(m)\n",
    "    \n",
    "    for fileName in sorted(fileList):\n",
    "        utterances.append(os.path.join(speaker,fileName))                \n",
    "    speakers.append(utterances)\n",
    "    \n",
    "with open(os.path.join(rootDir, 'train1.pkl'), 'wb') as handle:\n",
    "    pickle.dump(speakers, handle)\n",
    "#     print (speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('.', 'metadata1.pkl'), 'wb') as handle:\n",
    "    pickle.dump(metadata, handle)\n",
    "# for sbmt_i in metadata:\n",
    "#     print (len(sbmt_i))\n",
    "# metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go to the command line and run python main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "from model_vc import Generator\n",
    "\n",
    "\n",
    "def pad_seq(x, base=32):\n",
    "    len_out = int(base * ceil(float(x.shape[0])/base))\n",
    "    len_pad = len_out - x.shape[0]\n",
    "    assert len_pad >= 0\n",
    "    return np.pad(x, ((0,len_pad),(0,0)), 'constant'), len_pad\n",
    "\n",
    "device = 'cuda:1'\n",
    "# G = Generator(32,256,512,32).eval().to(device) # (dim_neck, dim_emb, dim_pre, freq):\n",
    "G = Generator(16,256,512,32).eval().to(device) # (dim_neck, dim_emb, dim_pre, freq):\n",
    "\n",
    "# g_checkpoint = torch.load('autovc_orig.ckpt')\n",
    "g_checkpoint = torch.load('autovc_499999.ckpt')\n",
    "\n",
    "G.load_state_dict(g_checkpoint['model'])\n",
    "\n",
    "metadata = pickle.load(open('metadata1.pkl', \"rb\"))\n",
    "\n",
    "spect_vc = []\n",
    "\n",
    "for sbmt_i in metadata:\n",
    "#     print (len(sbmt_i))\n",
    "#     print (sbmt_i[0])\n",
    "#     print (sbmt_i[1])\n",
    "#     print (sbmt_i[2])\n",
    "    x_org = sbmt_i[2]\n",
    "    x_org, len_pad = pad_seq(x_org)\n",
    "    uttr_org = torch.from_numpy(x_org[np.newaxis, :, :]).to(device)\n",
    "    emb_org = torch.from_numpy(sbmt_i[1][np.newaxis, :]).to(device)\n",
    "    for sbmt_j in metadata:\n",
    "        emb_trg = torch.from_numpy(sbmt_j[1][np.newaxis, :]).to(device)\n",
    "        with torch.no_grad():\n",
    "            _, x_identic_psnt, _ = G(uttr_org, emb_org, emb_trg)\n",
    "        if len_pad == 0:\n",
    "            uttr_trg = x_identic_psnt[0, 0, :, :].cpu().numpy()\n",
    "        else:\n",
    "            uttr_trg = x_identic_psnt[0, 0, :-len_pad, :].cpu().numpy()\n",
    "        spect_vc.append( ('{}x{}'.format(sbmt_i[0], sbmt_j[0]), uttr_trg) )\n",
    "with open('results1.pkl', 'wb') as handle:\n",
    "    pickle.dump(spect_vc, handle)    \n",
    "    \n",
    "import torch\n",
    "import librosa\n",
    "import pickle\n",
    "from synthesis import build_model\n",
    "from synthesis import wavegen\n",
    "\n",
    "spect_vc = pickle.load(open('results1.pkl', 'rb'))\n",
    "device = torch.device(\"cuda\")\n",
    "model = build_model().to(device)\n",
    "checkpoint = torch.load(\"checkpoint_step001000000_ema.pth\")\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "for spect in spect_vc:\n",
    "    name = spect[0]\n",
    "    c = spect[1]\n",
    "    print(name)\n",
    "    waveform = wavegen(model, c=c)   \n",
    "    librosa.output.write_wav(name+'.wav', waveform, sr=16000)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
